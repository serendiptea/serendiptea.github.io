<!DOCTYPE html>
<html lang="en">
<head>
    <meta name="viewport" content="width=device-width, initial-scale=1"/>
    <title>Books: Invisible Women</title>
    <link rel="icon" href="logo_teapot.png">
    <link rel="stylesheet" href="style.css">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Roboto&family=Roboto+Mono:wght@300&display=swap" rel="stylesheet">
    <script src="index.js" defer></script>
</head>

<body style="background-color:rgb(245,245,220);">
  <a href="index.html" class="logo"><img src="main_logo.jpg" class="logo"></a>
  <div class="line"></div>
  <div class="sections_buttons">
        <a href="index.html" class="button">About</a>
        <a href="blog_books_page.html" class="button"><u>Books</u></a>
        <a href="blog_gallery_page.html" class="button">Gallery</a>
        <a href="blog_interviews_page.html" class="button">WoW</a>
        <a href="blog_food_page.html" class="button">Food</a>
  </div>
  <div class="line"></div>

  <p class="title">Invisible Women: Exposing Data Bias in a World Designed for Men</p>
  <p class="paragraph">Caroline Criado-Perez</p>
  <p class="paragraph">01/11/2023</p>

  <div class="article_intro">
          <div class="article_image_container">
              <img class="article_image" src="article_images/invisible_women.png">
          </div>
          <div class="article_summary_container">
              <p class="article_summary">Dear readers,</p>
              <p class="article_summary">
                  This month, we are risking it all by dropping the feminist bomb. This article is a scary one, as much for you to read as for us to write,
                  but worry not, we are available for moral support. We’ve summarized some interesting ideas developed by Caroline Criado-Perez in her book,
                  “Invisible Women”, to enlighten you on some issues unique to the female experience. This dense 300-page read analyses and explains the unspoken
                  data gaps that are affecting women’s career opportunities, health, and economic opportunities; in short, their lives.

              </p>

              <p class="article_summary">
                  Fun fact time! Did you know that a woman’s body is different from a man’s? It may seem obvious, but many scientists choose to ignore it.
                  From the development and testing of drugs, the design of vehicles, technologies, this fact has been repeatedly ignored. Vehicle crash tests,
                  to this day, do not require the use of female dummies. And when they graciously are, they are often just scaled down male dummies.
                  This is an issue because big morphological and anatomical differences are completely ignored with the assumption that female bodies are just a
                  smaller version of a man’s. Could that be why women are 47% more likely than men to suffer from severe injuries in a car accident?
              </p>
          </div>
  </div>

  <p class="paragraph">
      Another key data gap explored in this book is unpaid domestic work, 75% of which is done by women. This essential work – cooking, cleaning, taking care of children,
      relatives, running errands, without which society would fall apart–  is perceived as an unlimited free resource to exploit. This domestic workload increases in
      heterosexual couples, resulting in an extra 7 hours of housework for women. But the impact of redistributing this load is drastic: a mother’s future earnings increase by
      an average of 7% for every month of paternal leave taken by the father!
  </p>

  <p class="paragraph">
      This data gap extends even further, to the new interviewing practices, meant to eliminate gender discrimination but actually involuntarily perpetuating it. A great example is
      the use of robots in interviews trained on posture, facial expressions and vocal tone to identify ‘top-performing employees’. But you guessed it, when these models are men,
      those are the applications that the algorithms will push forward. A prime example is the hiring algorithms used in tech: aptitude tests for computer science jobs are framed
      around typical male behavior, sometimes going so far as to track the candidates activity on coding blogs, thus eliminating perfectly apt candidates that don’t exhibit this
      typically male behavior.
  </p>

  <p class="final_paragraph">
  All this information may seem overwhelmingly pessimistic, but trust us this is only a brief summary ;) On a more serious note, many of these biases are not intentional and they could easily be
      prevented with adequate data-driven decisions and the involvement of more women decision-making. The solutions are plenty, and would benefit society as a whole. All the more reason to be
      more educated on how these biases operate.
  </p>


<div class="line"></div>
  <div class="bottom">
        <p class="paragraph_bottom">Follow us on:</p>
        <a class="insta_logo" href="https://www.instagram.com/serendipi__tea/?igshid=NTc4MTIwNjQ2YQ%3D%3D" target="_blank"><img class="insta_logo_image" src="insta_logo.png"></a>
        <a class="insta_link" href="https://www.instagram.com/serendipi__tea/?igshid=NTc4MTIwNjQ2YQ%3D%3D" target="_blank">Instagram</a>
  </div>
  <div class="line"></div>

</body>
</html>